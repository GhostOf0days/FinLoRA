{
  "finer_llama_3_1_8B_8bits_r8": {
    "base_model": "NousResearch/Meta-Llama-3.1-8B-Instruct",
    "dataset_path": "../data/train/finer_train_batched.jsonl",
    "lora_r": 8,
    "quant_bits": 8,
    "learning_rate": 0.0001,
    "num_epochs": 4,
    "batch_size": 2,
    "gradient_accumulation_steps": 4
  },
  "finer_llama_3_1_8B_4bits_r4": {
    "base_model": "NousResearch/Meta-Llama-3.1-8B-Instruct",
    "dataset_path": "../data/train/finer_train.jsonl",
    "lora_r": 4,
    "quant_bits": 4,
    "learning_rate": 0.0002,
    "num_epochs": 4,
    "batch_size": 2,
    "gradient_accumulation_steps": 4
  }
}